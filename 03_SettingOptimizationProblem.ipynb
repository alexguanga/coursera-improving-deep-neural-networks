{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up your optimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing inputs\n",
    "When normalizing the inputs, the goal is to transform the values where the values are around 0 (0 will be the mean)\n",
    "1. Subract each value from the average of all values\n",
    "2. Divide the variance of all the values from the result in step 1 \n",
    "\n",
    "<img src=\"./images/improv_11.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Scale the training set and testing set\n",
    "- <img src=\"./images/improv_12.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "- Noticed that if we scale, then when use gradient descent, we are more likely to have find the local minima in an efficient manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing / Exploding gradients\n",
    "You are performing these network, the derivative could either be very large or very small\n",
    "\n",
    "In the example below, we must think of the layers as being linear. Thus y_hat could use the function in the image below.\n",
    "\n",
    "<img src=\"./images/improv_50.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "\n",
    "The image above explains that when train on a deep neural network, one difficutlies is that are weight could increase/decrease exponentially as we go further in the layers. Hence, the weights deeper in the network will not carry much weight. \n",
    "\n",
    "The image above is not an accurate representation of a deep layer network since we do not have an activation function. It does serves the purpose of displaying how using the same weight throughout the network could be an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Initialization for Deep Networks\n",
    "\n",
    "<img src=\"./images/improv_51.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "\n",
    "As we learned in the previous section, the weights must be a well-thought out process. A partial solution would be to intialize the weights by the total number of inputs/output from the activation function. Therefore, the weights will decrease across all layers to a certain proportion that can reduce the possibility of exploding/vanishing gradient descent. \n",
    "\n",
    "The formulas used are in the image above.\n",
    "\n",
    "Since we do not want to suffer from the vanishing/exploding gradient, this method helps our weight remain close to 1. \n",
    "\n",
    "```python\n",
    "# relu function\n",
    "W_layer_1 = np.random.rand(shape)*np.sqrt(2/n_layer_minus_1)\n",
    "\n",
    "# tanh function\n",
    "W_layer_1 = np.random.rand(shape)*np.sqrt(1/n_layer_minus_1)\n",
    "\n",
    "# xavier initilization function\n",
    "W_layer_1 = np.random.rand(shape)*np.sqrt(2/(n_layer_minus_1+n_layer_1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical approximation of gradients\n",
    "- <img src=\"./images/improv_14.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "\n",
    "The idea is that we are creating the 'triangle' using the epilson (plus and negative) to get a closer approx. to the actual gradient. When we use a larger scope, our gradient is more accurate.\n",
    "\n",
    "Intersting: Our epilson error depends on whether we are using epilson or 2 * epilson.\n",
    "- <img src=\"./images/improv_15.png\" alt=\"Drawing\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient checking\n",
    "\n",
    "This section is useful when you have to debug any issues in the calculations. Your goal is to find if the derivative is the actual derivative of the cost fuction...\n",
    "\n",
    "Gradient check for a neural network:\n",
    "- Take $W^{[1]}$, $b^{[1]}$, ..., $W^{[L]}$, $b^{[L]}$ and reshape into a large vector delta.\n",
    "- Take $dW^{[1]}$, $db^{[1]}$, ..., $dW^{[L]}$, $db^{[L]}$ and reshape into a large vector d_delta.\n",
    "\n",
    "\n",
    "<img src=\"./images/improv_16.png\" alt=\"Drawing\" style=\"width: 550px;\"/>\n",
    "\n",
    "- Noticed that we compute the approx, and then compare it with the gradient we actually got.\n",
    "- Thus, we can use the Eucidean distances to find the distance btw computed and calculated gradient descent.\n",
    "- In the image, he provides thresholds of acceptables differences versus non-acceptables differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Checking Implementation Notes\n",
    "\n",
    "Gradient checking implementation notes:\n",
    "- Don't use in training-only to debug\n",
    "- If algoirthm fails grad check, look at components to try to identify bug.\n",
    "    - e.g. there are only some layers for only b's\n",
    "- Remember regularization.\n",
    "- Doesn't work with dropout because we cannot mimic the neuron that are being dropped out.\n",
    "    - We could turn on keep.prop to 1.0 just to check."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
