{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up your Machine Learning Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Dev/Test sets\n",
    "\n",
    "- Analyzing all the hyperparameters/parameters could be cumbersome\n",
    "    - E.g. layers, hidden units, learning rates, activation functions\n",
    "- The application could be in NLP, Vision, Speech, Structure Data (Ads, Search, Security, Logistic)\n",
    "- It is very hard to guess the corrrect hyperparameters from the get.\n",
    "\n",
    "The idea of train/dev/test sets is that you will have data...\n",
    "- and you split the data to 3-parts: training set, development (hold-out) set, and testing set.\n",
    "\n",
    "Things have changed since more data could be collected. Before, a common rule, was to have a 70/30/30 split. Now, it tends to be more of 98/1/1 split where most of the data is used to train the model.\n",
    "\n",
    "You must reassure that the dev/test set come from the same distribution. \n",
    "- You do not want the dev set to have photos coming from the web (high-resolution) while test set are pictures taken from a phone.\n",
    "\n",
    "Sometimes, you do not need a test set. You train on the training set and evaluate on the dev set.\n",
    "\n",
    "Links\n",
    "- [Difference between train/validation/testing set](https://stackoverflow.com/questions/2976452/whats-is-the-difference-between-train-validation-and-test-set-in-neural-netwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias / Variance\n",
    "In machine learning, I am quite aware of the bias/variance trade-off. However, Andrew explains that the concept remain but the trade is not as applicable as it was in machine learning.\n",
    "\n",
    "<img src=\"./images/improv_1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Example 1: \n",
    "\n",
    "| Train set error | Dev set error | \n",
    "| --- | --- | \n",
    "| 1% | 11% |\n",
    "\n",
    "- **High Variance problem.**\n",
    "    - Since the data is fitting to well (low error %) on the training set error while there's a huge drop in error % when the same model is predicting the development set. \n",
    "    - Think of it as when you have high variance, the results are more sparsely because we the model overfits the training set.\n",
    "\n",
    "Example 2: \n",
    "\n",
    "| Train set error | Dev set error | \n",
    "| --- | --- | \n",
    "| 15% | 16% |\n",
    "\n",
    "- **High Bias problem.**\n",
    "    - This model is not even doing well on training set. Hence. the algorithm has a high bias. It is not even fitting the training set.\n",
    "    \n",
    "Example 3: \n",
    "\n",
    "| Train set error | Dev set error | \n",
    "| --- | --- | \n",
    "| 15% | 30% | \n",
    "\n",
    "- We have a high bias and high variance problem. \n",
    "- This could happen if for some the data we overfit while in parts of the data we are underfitting.\n",
    "\n",
    "<img src=\"./images/improv_2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "    \n",
    "- **REMEMBER: THAT WHEN THE DATA HAS A HIGH BIAS, WE ARE UNDERFITTING THE DATA. MEANING, OUR MODEL IS BIASED THAT IT WILL NOT EVEN PERFORM WILL FOR OUR TRAINING SET.**\n",
    "\n",
    "- **REMEMBER: THAT WHEN THE DATA HAS A HIGH VARIANCE, WE ARE OVERFITTING THE DATA. MEANING, OUR DATA WILL ONLY PERFORM WILL IN OUR TRAINING SET, AND NOT IN OUR DEV SET**\n",
    "\n",
    "Optimal (Bayes Error) is 0%. If this were much higher (15%) then a 15% error on train set is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Recipe for Machine Learning\n",
    "\n",
    "**Reducing bias (high bias); this could be viewed in the training set performance. If it cannot train well on the training set, this has a high bias.**\n",
    "1. You could have a bigger network (more hidden layers)\n",
    "2. You can train it longer. \n",
    "3. You can restructure the NN archiecture. (This is one does not always help)\n",
    "\n",
    "**Reducing variance (high variance); this could be viewed in the dev set performance. If it performs well on the training set but not the dev set, we are overfitting, or a high variance.**\n",
    "1. More data\n",
    "2. Regularization\n",
    "3. You can restructure the NN archiecture. (This is one does not always help)\n",
    "\n",
    "Before deep learning, there was the bias-variance trade-off. However, with deep learning, we now have tools that can reduce both (without hurting either of them)\n",
    "- For reducing bias, we can add more layers. This will not hurt the variance.\n",
    "    - With more layers, we are allowing the model to be more complicated and thus, learn the underlying structure of the data.\n",
    "- For reducing variance, we can have more data. This will not hurt the bias.\n",
    "    - With more data, we are helping the model not overfit. We are giving it more data where the model will find more patterns that is not solely predicated on the training set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
